{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummaryX import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "from UnarySim.sw.kernel.nn_utils import *\n",
    "from UnarySim.sw.kernel.linear import UnaryLinear\n",
    "from UnarySim.sw.kernel.relu import UnaryReLU\n",
    "from UnarySim.sw.stream.gen import RNG, SourceGen, BSGen\n",
    "from UnarySim.sw.metric.metric import ProgressiveError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data loader\n",
    "transform=transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=cwd+'/data/mnist', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root=cwd+'/data/mnist', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_width = 16384\n",
    "total_epoch = min(int(layer_width / 512 * 20), 200)\n",
    "lr = 0.0001\n",
    "print(total_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LeNet()\n",
    "# model = LeNet_clamp()\n",
    "model = MLP3(layer_width)\n",
    "# model = MLP3_clamp()\n",
    "# model = MLP3_clamp_train()\n",
    "model.to(device)\n",
    "summary(model, torch.zeros((1, 1, 32, 32)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "clipper = NN_SC_Weight_Clipper(bitwidth=bitwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(total_epoch):  # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    model.apply(clipper)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Train - Epoch %d, Loss: %f, Test Accuracy: %f %%' \\\n",
    "          % (epoch, loss.detach().cpu().item(), 100 * correct / total))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = cwd+\"\\saved_model_state_dict\"+\"_8_clamp\"\n",
    "model_clamp = MLP3_clamp_eval()\n",
    "model_clamp.to(device)\n",
    "model_clamp.load_state_dict(torch.load(model_path))\n",
    "model_clamp.eval()\n",
    "model_clamp.to(device)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model_clamp(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(total_epoch):  # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    model.apply(clipper)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Train - Epoch %d, Loss: %f, Test Accuracy: %f %%' \\\n",
    "          % (epoch, loss.detach().cpu().item(), 100 * correct / total))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "binary sum:  tensor(85.3359, grad_fn=<SumBackward0>)\n",
      "\n",
      "unary sum:  tensor(85.3750)\n",
      "\n",
      "binary grad:  <bound method Tensor.retain_grad of Parameter containing:\n",
      "tensor([-1.0000, -0.9922, -0.9844, -0.9766, -0.9688, -0.9609, -0.9531, -0.9453,\n",
      "        -0.9375, -0.9297, -0.9219, -0.9141, -0.9062, -0.8984, -0.8906, -0.8828,\n",
      "        -0.8750, -0.8672, -0.8594, -0.8516, -0.8438, -0.8359, -0.8281, -0.8203,\n",
      "        -0.8125, -0.8047, -0.7969, -0.7891, -0.7812, -0.7734, -0.7656, -0.7578,\n",
      "        -0.7500, -0.7422, -0.7344, -0.7266, -0.7188, -0.7109, -0.7031, -0.6953,\n",
      "        -0.6875, -0.6797, -0.6719, -0.6641, -0.6562, -0.6484, -0.6406, -0.6328,\n",
      "        -0.6250, -0.6172, -0.6094, -0.6016, -0.5938, -0.5859, -0.5781, -0.5703,\n",
      "        -0.5625, -0.5547, -0.5469, -0.5391, -0.5312, -0.5234, -0.5156, -0.5078,\n",
      "        -0.5000, -0.4922, -0.4844, -0.4766, -0.4688, -0.4609, -0.4531, -0.4453,\n",
      "        -0.4375, -0.4297, -0.4219, -0.4141, -0.4062, -0.3984, -0.3906, -0.3828,\n",
      "        -0.3750, -0.3672, -0.3594, -0.3516, -0.3438, -0.3359, -0.3281, -0.3203,\n",
      "        -0.3125, -0.3047, -0.2969, -0.2891, -0.2812, -0.2734, -0.2656, -0.2578,\n",
      "        -0.2500, -0.2422, -0.2344, -0.2266, -0.2188, -0.2109, -0.2031, -0.1953,\n",
      "        -0.1875, -0.1797, -0.1719, -0.1641, -0.1562, -0.1484, -0.1406, -0.1328,\n",
      "        -0.1250, -0.1172, -0.1094, -0.1016, -0.0938, -0.0859, -0.0781, -0.0703,\n",
      "        -0.0625, -0.0547, -0.0469, -0.0391, -0.0312, -0.0234, -0.0156, -0.0078,\n",
      "         0.0000,  0.0078,  0.0156,  0.0234,  0.0312,  0.0391,  0.0469,  0.0547,\n",
      "         0.0625,  0.0703,  0.0781,  0.0859,  0.0938,  0.1016,  0.1094,  0.1172,\n",
      "         0.1250,  0.1328,  0.1406,  0.1484,  0.1562,  0.1641,  0.1719,  0.1797,\n",
      "         0.1875,  0.1953,  0.2031,  0.2109,  0.2188,  0.2266,  0.2344,  0.2422,\n",
      "         0.2500,  0.2578,  0.2656,  0.2734,  0.2812,  0.2891,  0.2969,  0.3047,\n",
      "         0.3125,  0.3203,  0.3281,  0.3359,  0.3438,  0.3516,  0.3594,  0.3672,\n",
      "         0.3750,  0.3828,  0.3906,  0.3984,  0.4062,  0.4141,  0.4219,  0.4297,\n",
      "         0.4375,  0.4453,  0.4531,  0.4609,  0.4688,  0.4766,  0.4844,  0.4922,\n",
      "         0.5000,  0.5078,  0.5156,  0.5234,  0.5312,  0.5391,  0.5469,  0.5547,\n",
      "         0.5625,  0.5703,  0.5781,  0.5859,  0.5938,  0.6016,  0.6094,  0.6172,\n",
      "         0.6250,  0.6328,  0.6406,  0.6484,  0.6562,  0.6641,  0.6719,  0.6797,\n",
      "         0.6875,  0.6953,  0.7031,  0.7109,  0.7188,  0.7266,  0.7344,  0.7422,\n",
      "         0.7500,  0.7578,  0.7656,  0.7734,  0.7812,  0.7891,  0.7969,  0.8047,\n",
      "         0.8125,  0.8203,  0.8281,  0.8359,  0.8438,  0.8516,  0.8594,  0.8672,\n",
      "         0.8750,  0.8828,  0.8906,  0.8984,  0.9062,  0.9141,  0.9219,  0.9297,\n",
      "         0.9375,  0.9453,  0.9531,  0.9609,  0.9688,  0.9766,  0.9844,  0.9922],\n",
      "       requires_grad=True)>\n"
     ]
    }
   ],
   "source": [
    "correct_binary = 0\n",
    "correct_unary = 0\n",
    "\n",
    "bitwidth = 8\n",
    "total = 0\n",
    "\n",
    "# binary MLP3_clamp weight init\n",
    "rng = \"Sobol\"\n",
    "encode = \"RC\"\n",
    "rng_dim = 1\n",
    "relu_buf_dep = 4\n",
    "mode = \"bipolar\"\n",
    "scaled = False\n",
    "bias = True\n",
    "sample_cnt = 1000\n",
    "\n",
    "start_cnt = 0\n",
    "current_index = 0\n",
    "\n",
    "cycle_correct = torch.zeros(2**(bitwidth)).to(device)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        if current_index < start_cnt:\n",
    "            current_index = current_index + 1\n",
    "            continue\n",
    "        current_index = current_index + 1\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # reference binary mlp\n",
    "        outputs_binary = model_clamp(images)\n",
    "        _, predicted_binary = torch.max(outputs_binary.data, 1)\n",
    "        correct_binary += (predicted_binary == labels).sum().item()\n",
    "        \n",
    "#         print(model_clamp.fc1_out.min().item(), model_clamp.fc1_out.max().item())\n",
    "#         print(model_clamp.fc2_out.min().item(), model_clamp.fc2_out.max().item())\n",
    "#         print(model_clamp.fc3_out.min().item(), model_clamp.fc3_out.max().item())\n",
    "\n",
    "\n",
    "        # unary part\n",
    "        # input image check\n",
    "        image = images.view(-1, 32*32)\n",
    "        image_SRC = SourceGen(image, bitwidth=bitwidth, mode=mode)().to(device)\n",
    "        image_RNG = RNG(bitwidth, rng_dim, rng)().to(device)\n",
    "        image_BSG = BSGen(image_SRC, image_RNG).to(device)\n",
    "        image_ERR = ProgressiveError(image, mode=mode).to(device)\n",
    "        \n",
    "        # unary mlp is decomposed into separate layers\n",
    "        fc1_unary = UnaryLinear(32*32, 512, model_clamp.fc1.weight.data, model_clamp.fc1.bias.data, \n",
    "                        mode=mode, scaled=scaled, bias=bias).to(device)\n",
    "        fc1_ERR = ProgressiveError(model_clamp.fc1_out, mode=mode).to(device)\n",
    "        \n",
    "        fc2_unary = UnaryLinear(512, 512, model_clamp.fc2.weight.data, model_clamp.fc2.bias.data, \n",
    "                                mode=mode, scaled=scaled, bias=bias).to(device)\n",
    "        fc2_ERR = ProgressiveError(model_clamp.fc2_out, mode=mode).to(device)\n",
    "\n",
    "        fc3_unary = UnaryLinear(512, 10, model_clamp.fc3.weight.data, model_clamp.fc3.bias.data, \n",
    "                                mode=mode, scaled=scaled, bias=bias).to(device)\n",
    "        fc3_ERR = ProgressiveError(model_clamp.fc3_out, mode=mode).to(device)\n",
    "        \n",
    "        relu1_unary = UnaryReLU(depth=relu_buf_dep, bitwidth=bitwidth, encode=encode).to(device)\n",
    "        relu1_ERR = ProgressiveError(model_clamp.relu1_out, mode=mode).to(device)\n",
    "        \n",
    "        relu2_unary = UnaryReLU(depth=relu_buf_dep, bitwidth=bitwidth, encode=encode).to(device)\n",
    "        relu2_ERR = ProgressiveError(model_clamp.relu2_out, mode=mode).to(device)\n",
    "        \n",
    "        if total%100 == 0:\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "            print(total, \"images are done!!!\")\n",
    "\n",
    "#         print(current_index, \"-th image with label\", labels.item(), \", total image count\", total)\n",
    "        for i in range(2**(bitwidth)):\n",
    "            idx = torch.zeros(image_SRC.size()).type(torch.long).to(device)\n",
    "            image_bs = image_BSG(idx + i)\n",
    "            image_ERR.Monitor(image_bs)\n",
    "            # print(image_bs.shape)\n",
    "            # fc1\n",
    "            fc1_unary_out   = fc1_unary(image_bs)\n",
    "#             fc1_ERR.Monitor(fc1_unary_out)\n",
    "            # print(fc1_unary_out.shape)\n",
    "            # relu1\n",
    "            relu1_unary_out = relu1_unary(fc1_unary_out)\n",
    "#             relu1_ERR.Monitor(relu1_unary_out)\n",
    "            # print(relu1_unary_out.shape)\n",
    "            # fc2\n",
    "            fc2_unary_out   = fc2_unary(relu1_unary_out)\n",
    "#             fc2_ERR.Monitor(fc2_unary_out)\n",
    "            # print(fc2_unary_out.shape)\n",
    "            # relu2\n",
    "            relu2_unary_out = relu2_unary(fc2_unary_out)\n",
    "#             relu2_ERR.Monitor(relu2_unary_out)\n",
    "            # print(relu2_unary_out.shape)\n",
    "            # fc3\n",
    "            fc3_unary_out   = fc3_unary(relu2_unary_out)\n",
    "            fc3_ERR.Monitor(fc3_unary_out)\n",
    "            # print(fc3_unary_out.shape)\n",
    "            \n",
    "            _, predicted_unary = torch.max(fc3_ERR()[0], 1)\n",
    "            if predicted_unary == labels:\n",
    "#                 print(current_index, \"-th image succeeds.\")\n",
    "#                 print(current_index, \"-th image with label\", labels.item(), \", total image count\", total)\n",
    "#                 print(\"before\", predicted_unary.item(), cycle_correct[predicted_unary.item()].item())\n",
    "                cycle_correct[i].add_(1)\n",
    "#                 print(\"after\", predicted_unary.item(), cycle_correct[predicted_unary.item()].item())\n",
    "\n",
    "#         to_print = 1\n",
    "#         print(\"image: \", \n",
    "#               image_ERR()[to_print].min().item(), \n",
    "#               image_ERR()[to_print].max().item(),\n",
    "#               image_ERR()[to_print].mul(image_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"fc1:   \", \n",
    "#               fc1_ERR()[to_print].min().item(), \n",
    "#               fc1_ERR()[to_print].max().item(), \n",
    "#               fc1_ERR()[to_print].mul(fc1_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"relu1: \", \n",
    "#               relu1_ERR()[to_print].min().item(), \n",
    "#               relu1_ERR()[to_print].max().item(), \n",
    "#               relu1_ERR()[to_print].mul(relu1_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"fc2:   \", \n",
    "#               fc2_ERR()[to_print].min().item(), \n",
    "#               fc2_ERR()[to_print].max().item(), \n",
    "#               fc2_ERR()[to_print].mul(fc2_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"relu1: \", \n",
    "#               relu2_ERR()[to_print].min().item(), \n",
    "#               relu2_ERR()[to_print].max().item(), \n",
    "#               relu1_ERR()[to_print].mul(relu1_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"fc3:   \", \n",
    "#               fc3_ERR()[to_print].min().item(), \n",
    "#               fc3_ERR()[to_print].max().item(), \n",
    "#               fc3_ERR()[to_print].mul(fc3_ERR()[to_print]).mean().sqrt().item())\n",
    "        \n",
    "        _, predicted_unary = torch.max(fc3_ERR()[0], 1)\n",
    "        correct_unary += (predicted_unary == labels).sum().item()\n",
    "        if total == sample_cnt:\n",
    "            break\n",
    "\n",
    "print('Accuracy of the network on %d test images: %f %%' % (total,\n",
    "    100 * correct_binary / total))\n",
    "print('Accuracy of the network on %d test images: %f %%' % (total,\n",
    "    100 * correct_unary / total))\n",
    "\n",
    "result = cycle_correct.cpu().numpy()/total\n",
    "fig = plt.plot([i for i in range(2**bitwidth)], result)  # arguments are passed to np.histogram\n",
    "plt.title(\"Cycle level accuracy\")\n",
    "plt.show()\n",
    "\n",
    "with open(\"cycle_accuracy_mlp_nonscaled_clamp_early_termination_profiling.csv\", \"w+\") as f:\n",
    "    for i in result:\n",
    "        f.write(str(i)+\", \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
