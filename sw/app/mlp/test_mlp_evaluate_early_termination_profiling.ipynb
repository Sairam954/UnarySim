{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummaryX import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "from UnarySim.sw.kernel.nn_utils import *\n",
    "from UnarySim.sw.kernel.linear import UnaryLinear\n",
    "from UnarySim.sw.kernel.relu import UnaryReLU\n",
    "from UnarySim.sw.stream.gen import RNG, SourceGen, BSGen\n",
    "from UnarySim.sw.metric.metric import ProgressiveError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\project\\Anaconda3\\Lib\\site-packages\\UnarySim\\sw\\test\\mlp\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data loader\n",
    "transform=transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=cwd+'/data/mnist', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root=cwd+'/data/mnist', train=True, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test binary model clamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.856667 %\n"
     ]
    }
   ],
   "source": [
    "model_path = cwd+\"\\saved_model_state_dict\"+\"_8_clamp\"\n",
    "model_clamp = MLP3_clamp_eval()\n",
    "model_clamp.to(device)\n",
    "model_clamp.load_state_dict(torch.load(model_path))\n",
    "model_clamp.eval()\n",
    "model_clamp.to(device)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model_clamp(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test unary model nonscaled addition - clamp binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5.8349995613098145 seconds ---\n",
      "100 images are done!!!\n",
      "--- 130.17799925804138 seconds ---\n",
      "200 images are done!!!\n",
      "--- 257.26699924468994 seconds ---\n",
      "300 images are done!!!\n",
      "--- 387.87199902534485 seconds ---\n",
      "400 images are done!!!\n",
      "--- 508.0079984664917 seconds ---\n",
      "500 images are done!!!\n",
      "--- 629.3499553203583 seconds ---\n",
      "600 images are done!!!\n",
      "--- 753.8499562740326 seconds ---\n",
      "700 images are done!!!\n",
      "--- 877.3519551753998 seconds ---\n",
      "800 images are done!!!\n",
      "--- 999.1889548301697 seconds ---\n",
      "900 images are done!!!\n",
      "--- 1122.1389546394348 seconds ---\n",
      "1000 images are done!!!\n",
      "Accuracy of the network on 1000 test images: 87.800000 %\n",
      "Accuracy of the network on 1000 test images: 85.300000 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct_binary = 0\n",
    "correct_unary = 0\n",
    "\n",
    "bitwidth = 8\n",
    "total = 0\n",
    "\n",
    "# binary MLP3_clamp weight init\n",
    "rng = \"Sobol\"\n",
    "encode = \"RC\"\n",
    "rng_dim = 1\n",
    "relu_buf_dep = 4\n",
    "mode = \"bipolar\"\n",
    "scaled = False\n",
    "bias = True\n",
    "sample_cnt = 1000\n",
    "\n",
    "start_cnt = 0\n",
    "current_index = 0\n",
    "\n",
    "cycle_correct = torch.zeros(2**(bitwidth)).to(device)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        if current_index < start_cnt:\n",
    "            current_index = current_index + 1\n",
    "            continue\n",
    "        current_index = current_index + 1\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # reference binary mlp\n",
    "        outputs_binary = model_clamp(images)\n",
    "        _, predicted_binary = torch.max(outputs_binary.data, 1)\n",
    "        correct_binary += (predicted_binary == labels).sum().item()\n",
    "        \n",
    "#         print(model_clamp.fc1_out.min().item(), model_clamp.fc1_out.max().item())\n",
    "#         print(model_clamp.fc2_out.min().item(), model_clamp.fc2_out.max().item())\n",
    "#         print(model_clamp.fc3_out.min().item(), model_clamp.fc3_out.max().item())\n",
    "\n",
    "\n",
    "        # unary part\n",
    "        # input image check\n",
    "        image = images.view(-1, 32*32)\n",
    "        image_SRC = SourceGen(image, bitwidth=bitwidth, mode=mode)().to(device)\n",
    "        image_RNG = RNG(bitwidth, rng_dim, rng)().to(device)\n",
    "        image_BSG = BSGen(image_SRC, image_RNG).to(device)\n",
    "        image_ERR = ProgressiveError(image, mode=mode).to(device)\n",
    "        \n",
    "        # unary mlp is decomposed into separate layers\n",
    "        fc1_unary = UnaryLinear(32*32, 512, model_clamp.fc1.weight.data, model_clamp.fc1.bias.data, \n",
    "                        mode=mode, scaled=scaled, bias=bias).to(device)\n",
    "        fc1_ERR = ProgressiveError(model_clamp.fc1_out, mode=mode).to(device)\n",
    "        \n",
    "        fc2_unary = UnaryLinear(512, 512, model_clamp.fc2.weight.data, model_clamp.fc2.bias.data, \n",
    "                                mode=mode, scaled=scaled, bias=bias).to(device)\n",
    "        fc2_ERR = ProgressiveError(model_clamp.fc2_out, mode=mode).to(device)\n",
    "\n",
    "        fc3_unary = UnaryLinear(512, 10, model_clamp.fc3.weight.data, model_clamp.fc3.bias.data, \n",
    "                                mode=mode, scaled=scaled, bias=bias).to(device)\n",
    "        fc3_ERR = ProgressiveError(model_clamp.fc3_out, mode=mode).to(device)\n",
    "        \n",
    "        relu1_unary = UnaryReLU(depth=relu_buf_dep, bitwidth=bitwidth, encode=encode).to(device)\n",
    "        relu1_ERR = ProgressiveError(model_clamp.relu1_out, mode=mode).to(device)\n",
    "        \n",
    "        relu2_unary = UnaryReLU(depth=relu_buf_dep, bitwidth=bitwidth, encode=encode).to(device)\n",
    "        relu2_ERR = ProgressiveError(model_clamp.relu2_out, mode=mode).to(device)\n",
    "        \n",
    "        if total%100 == 0:\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "            print(total, \"images are done!!!\")\n",
    "\n",
    "#         print(current_index, \"-th image with label\", labels.item(), \", total image count\", total)\n",
    "        for i in range(2**(bitwidth)):\n",
    "            idx = torch.zeros(image_SRC.size()).type(torch.long).to(device)\n",
    "            image_bs = image_BSG(idx + i)\n",
    "            image_ERR.Monitor(image_bs)\n",
    "            # print(image_bs.shape)\n",
    "            # fc1\n",
    "            fc1_unary_out   = fc1_unary(image_bs)\n",
    "#             fc1_ERR.Monitor(fc1_unary_out)\n",
    "            # print(fc1_unary_out.shape)\n",
    "            # relu1\n",
    "            relu1_unary_out = relu1_unary(fc1_unary_out)\n",
    "#             relu1_ERR.Monitor(relu1_unary_out)\n",
    "            # print(relu1_unary_out.shape)\n",
    "            # fc2\n",
    "            fc2_unary_out   = fc2_unary(relu1_unary_out)\n",
    "#             fc2_ERR.Monitor(fc2_unary_out)\n",
    "            # print(fc2_unary_out.shape)\n",
    "            # relu2\n",
    "            relu2_unary_out = relu2_unary(fc2_unary_out)\n",
    "#             relu2_ERR.Monitor(relu2_unary_out)\n",
    "            # print(relu2_unary_out.shape)\n",
    "            # fc3\n",
    "            fc3_unary_out   = fc3_unary(relu2_unary_out)\n",
    "            fc3_ERR.Monitor(fc3_unary_out)\n",
    "            # print(fc3_unary_out.shape)\n",
    "            \n",
    "            _, predicted_unary = torch.max(fc3_ERR()[0], 1)\n",
    "            if predicted_unary == labels:\n",
    "#                 print(current_index, \"-th image succeeds.\")\n",
    "#                 print(current_index, \"-th image with label\", labels.item(), \", total image count\", total)\n",
    "#                 print(\"before\", predicted_unary.item(), cycle_correct[predicted_unary.item()].item())\n",
    "                cycle_correct[i].add_(1)\n",
    "#                 print(\"after\", predicted_unary.item(), cycle_correct[predicted_unary.item()].item())\n",
    "\n",
    "#         to_print = 1\n",
    "#         print(\"image: \", \n",
    "#               image_ERR()[to_print].min().item(), \n",
    "#               image_ERR()[to_print].max().item(),\n",
    "#               image_ERR()[to_print].mul(image_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"fc1:   \", \n",
    "#               fc1_ERR()[to_print].min().item(), \n",
    "#               fc1_ERR()[to_print].max().item(), \n",
    "#               fc1_ERR()[to_print].mul(fc1_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"relu1: \", \n",
    "#               relu1_ERR()[to_print].min().item(), \n",
    "#               relu1_ERR()[to_print].max().item(), \n",
    "#               relu1_ERR()[to_print].mul(relu1_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"fc2:   \", \n",
    "#               fc2_ERR()[to_print].min().item(), \n",
    "#               fc2_ERR()[to_print].max().item(), \n",
    "#               fc2_ERR()[to_print].mul(fc2_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"relu1: \", \n",
    "#               relu2_ERR()[to_print].min().item(), \n",
    "#               relu2_ERR()[to_print].max().item(), \n",
    "#               relu1_ERR()[to_print].mul(relu1_ERR()[to_print]).mean().sqrt().item())\n",
    "#         print(\"fc3:   \", \n",
    "#               fc3_ERR()[to_print].min().item(), \n",
    "#               fc3_ERR()[to_print].max().item(), \n",
    "#               fc3_ERR()[to_print].mul(fc3_ERR()[to_print]).mean().sqrt().item())\n",
    "        \n",
    "        _, predicted_unary = torch.max(fc3_ERR()[0], 1)\n",
    "        correct_unary += (predicted_unary == labels).sum().item()\n",
    "        if total == sample_cnt:\n",
    "            break\n",
    "\n",
    "print('Accuracy of the network on %d test images: %f %%' % (total,\n",
    "    100 * correct_binary / total))\n",
    "print('Accuracy of the network on %d test images: %f %%' % (total,\n",
    "    100 * correct_unary / total))\n",
    "\n",
    "result = cycle_correct.cpu().numpy()/total\n",
    "fig = plt.plot([i for i in range(2**bitwidth)], result)  # arguments are passed to np.histogram\n",
    "plt.title(\"Cycle level accuracy\")\n",
    "plt.show()\n",
    "\n",
    "with open(\"cycle_accuracy_mlp_nonscaled_clamp_early_termination_profiling.csv\", \"w+\") as f:\n",
    "    for i in result:\n",
    "        f.write(str(i)+\", \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
