{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummaryX import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "from UnarySim.sw.kernel.nn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\project\\Anaconda3\\Lib\\site-packages\\UnarySim\\sw\\test\\mlp\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data loader\n",
    "transform=transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=cwd+'/data/mnist', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root=cwd+'/data/mnist', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "layer_width = 16384\n",
    "total_epoch = min(int(layer_width / 512 * 20), 200)\n",
    "lr = 0.0001\n",
    "print(total_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "         Kernel Shape Output Shape      Params    Mult-Adds\n",
      "Layer                                                      \n",
      "0_fc1   [1024, 16384]   [1, 16384]    16.7936M   16.777216M\n",
      "1_do1               -   [1, 16384]           -            -\n",
      "2_fc2  [16384, 16384]   [1, 16384]  268.45184M  268.435456M\n",
      "3_do2               -   [1, 16384]           -            -\n",
      "4_fc3     [16384, 10]      [1, 10]     163.85k      163.84k\n",
      "------------------------------------------------------------\n",
      "                           Totals\n",
      "Total params           285.40929M\n",
      "Trainable params       285.40929M\n",
      "Non-trainable params          0.0\n",
      "Mult-Adds             285.376512M\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_fc1</th>\n",
       "      <td>[1024, 16384]</td>\n",
       "      <td>[1, 16384]</td>\n",
       "      <td>16793600.0</td>\n",
       "      <td>16777216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_do1</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 16384]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_fc2</th>\n",
       "      <td>[16384, 16384]</td>\n",
       "      <td>[1, 16384]</td>\n",
       "      <td>268451840.0</td>\n",
       "      <td>268435456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_do2</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 16384]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_fc3</th>\n",
       "      <td>[16384, 10]</td>\n",
       "      <td>[1, 10]</td>\n",
       "      <td>163850.0</td>\n",
       "      <td>163840.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Kernel Shape Output Shape       Params    Mult-Adds\n",
       "Layer                                                       \n",
       "0_fc1   [1024, 16384]   [1, 16384]   16793600.0   16777216.0\n",
       "1_do1               -   [1, 16384]          NaN          NaN\n",
       "2_fc2  [16384, 16384]   [1, 16384]  268451840.0  268435456.0\n",
       "3_do2               -   [1, 16384]          NaN          NaN\n",
       "4_fc3     [16384, 10]      [1, 10]     163850.0     163840.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = LeNet()\n",
    "# model = LeNet_clamp()\n",
    "model = MLP3(layer_width)\n",
    "# model = MLP3_clamp()\n",
    "# model = MLP3_clamp_train()\n",
    "model.to(device)\n",
    "summary(model, torch.zeros((1, 1, 32, 32)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "clipper = NN_SC_Weight_Clipper(bitwidth=bitwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch 0, Loss: 1.523641, Test Accuracy: 94.940000 %\n",
      "Train - Epoch 1, Loss: 1.515995, Test Accuracy: 92.360000 %\n",
      "Train - Epoch 2, Loss: 1.561596, Test Accuracy: 93.310000 %\n",
      "Train - Epoch 3, Loss: 1.596567, Test Accuracy: 93.250000 %\n",
      "Train - Epoch 4, Loss: 1.544771, Test Accuracy: 93.450000 %\n",
      "Train - Epoch 5, Loss: 1.544534, Test Accuracy: 94.040000 %\n",
      "Train - Epoch 6, Loss: 1.690317, Test Accuracy: 93.150000 %\n",
      "Train - Epoch 7, Loss: 1.534067, Test Accuracy: 94.050000 %\n",
      "Train - Epoch 8, Loss: 1.544484, Test Accuracy: 93.900000 %\n",
      "Train - Epoch 9, Loss: 1.534067, Test Accuracy: 94.330000 %\n",
      "Train - Epoch 10, Loss: 1.586151, Test Accuracy: 94.410000 %\n",
      "Train - Epoch 11, Loss: 1.554902, Test Accuracy: 93.780000 %\n",
      "Train - Epoch 12, Loss: 1.502823, Test Accuracy: 93.860000 %\n",
      "Train - Epoch 13, Loss: 1.554901, Test Accuracy: 94.130000 %\n",
      "Train - Epoch 14, Loss: 1.575735, Test Accuracy: 94.210000 %\n",
      "Train - Epoch 15, Loss: 1.560897, Test Accuracy: 93.940000 %\n",
      "Train - Epoch 16, Loss: 1.562357, Test Accuracy: 94.300000 %\n",
      "Train - Epoch 17, Loss: 1.544484, Test Accuracy: 94.780000 %\n",
      "Train - Epoch 18, Loss: 1.586151, Test Accuracy: 94.550000 %\n",
      "Train - Epoch 19, Loss: 1.534067, Test Accuracy: 93.810000 %\n",
      "Train - Epoch 20, Loss: 1.575734, Test Accuracy: 93.810000 %\n",
      "Train - Epoch 21, Loss: 1.601365, Test Accuracy: 94.310000 %\n",
      "Train - Epoch 22, Loss: 1.544484, Test Accuracy: 93.630000 %\n",
      "Train - Epoch 23, Loss: 1.544484, Test Accuracy: 93.910000 %\n",
      "Train - Epoch 24, Loss: 1.565317, Test Accuracy: 93.980000 %\n",
      "Train - Epoch 25, Loss: 1.586151, Test Accuracy: 93.830000 %\n",
      "Train - Epoch 26, Loss: 1.523651, Test Accuracy: 94.000000 %\n",
      "Train - Epoch 27, Loss: 1.554901, Test Accuracy: 93.690000 %\n",
      "Train - Epoch 28, Loss: 1.595814, Test Accuracy: 92.010000 %\n",
      "Train - Epoch 29, Loss: 1.617401, Test Accuracy: 88.450000 %\n",
      "Train - Epoch 30, Loss: 1.595923, Test Accuracy: 91.030000 %\n",
      "Train - Epoch 31, Loss: 1.523651, Test Accuracy: 92.140000 %\n",
      "Train - Epoch 32, Loss: 1.617401, Test Accuracy: 93.270000 %\n",
      "Train - Epoch 33, Loss: 1.534067, Test Accuracy: 93.880000 %\n",
      "Train - Epoch 34, Loss: 1.575734, Test Accuracy: 94.360000 %\n",
      "Train - Epoch 35, Loss: 1.544484, Test Accuracy: 94.340000 %\n",
      "Train - Epoch 36, Loss: 1.544484, Test Accuracy: 94.410000 %\n",
      "Train - Epoch 37, Loss: 1.544484, Test Accuracy: 94.450000 %\n",
      "Train - Epoch 38, Loss: 1.523664, Test Accuracy: 94.520000 %\n",
      "Train - Epoch 39, Loss: 1.554901, Test Accuracy: 93.440000 %\n",
      "Train - Epoch 40, Loss: 1.564960, Test Accuracy: 94.270000 %\n",
      "Train - Epoch 41, Loss: 1.524173, Test Accuracy: 94.270000 %\n",
      "Train - Epoch 42, Loss: 1.596567, Test Accuracy: 94.200000 %\n",
      "Train - Epoch 43, Loss: 1.617984, Test Accuracy: 94.030000 %\n",
      "Train - Epoch 44, Loss: 1.648651, Test Accuracy: 94.260000 %\n",
      "Train - Epoch 45, Loss: 1.575734, Test Accuracy: 93.550000 %\n",
      "Train - Epoch 46, Loss: 1.554901, Test Accuracy: 94.040000 %\n",
      "Train - Epoch 47, Loss: 1.606984, Test Accuracy: 94.170000 %\n",
      "Train - Epoch 48, Loss: 1.596567, Test Accuracy: 93.610000 %\n",
      "Train - Epoch 49, Loss: 1.565317, Test Accuracy: 93.690000 %\n",
      "Train - Epoch 50, Loss: 1.502817, Test Accuracy: 94.720000 %\n",
      "Train - Epoch 51, Loss: 1.492401, Test Accuracy: 94.410000 %\n",
      "Train - Epoch 52, Loss: 1.502817, Test Accuracy: 94.480000 %\n",
      "Train - Epoch 53, Loss: 1.564963, Test Accuracy: 94.560000 %\n",
      "Train - Epoch 54, Loss: 1.513234, Test Accuracy: 94.310000 %\n",
      "Train - Epoch 55, Loss: 1.554901, Test Accuracy: 94.330000 %\n",
      "Train - Epoch 56, Loss: 1.502817, Test Accuracy: 94.160000 %\n",
      "Train - Epoch 57, Loss: 1.565317, Test Accuracy: 94.390000 %\n",
      "Train - Epoch 58, Loss: 1.534067, Test Accuracy: 94.560000 %\n",
      "Train - Epoch 59, Loss: 1.554901, Test Accuracy: 94.440000 %\n",
      "Train - Epoch 60, Loss: 1.544396, Test Accuracy: 93.500000 %\n",
      "Train - Epoch 61, Loss: 1.544484, Test Accuracy: 93.780000 %\n",
      "Train - Epoch 62, Loss: 1.565317, Test Accuracy: 94.360000 %\n",
      "Train - Epoch 63, Loss: 1.523651, Test Accuracy: 94.740000 %\n",
      "Train - Epoch 64, Loss: 1.565317, Test Accuracy: 94.870000 %\n",
      "Train - Epoch 65, Loss: 1.504897, Test Accuracy: 94.490000 %\n",
      "Train - Epoch 66, Loss: 1.513234, Test Accuracy: 94.550000 %\n",
      "Train - Epoch 67, Loss: 1.544286, Test Accuracy: 94.890000 %\n",
      "Train - Epoch 68, Loss: 1.534067, Test Accuracy: 94.490000 %\n",
      "Train - Epoch 69, Loss: 1.544484, Test Accuracy: 94.160000 %\n",
      "Train - Epoch 70, Loss: 1.554901, Test Accuracy: 94.270000 %\n",
      "Train - Epoch 71, Loss: 1.523651, Test Accuracy: 93.490000 %\n",
      "Train - Epoch 72, Loss: 1.534067, Test Accuracy: 93.620000 %\n",
      "Train - Epoch 73, Loss: 1.523651, Test Accuracy: 94.580000 %\n",
      "Train - Epoch 74, Loss: 1.544484, Test Accuracy: 94.310000 %\n",
      "Train - Epoch 75, Loss: 1.534067, Test Accuracy: 93.810000 %\n",
      "Train - Epoch 76, Loss: 1.502817, Test Accuracy: 94.110000 %\n",
      "Train - Epoch 77, Loss: 1.513234, Test Accuracy: 94.150000 %\n",
      "Train - Epoch 78, Loss: 1.565374, Test Accuracy: 93.190000 %\n",
      "Train - Epoch 79, Loss: 1.544484, Test Accuracy: 93.420000 %\n",
      "Train - Epoch 80, Loss: 1.523651, Test Accuracy: 93.800000 %\n",
      "Train - Epoch 81, Loss: 1.627817, Test Accuracy: 93.440000 %\n",
      "Train - Epoch 82, Loss: 1.492401, Test Accuracy: 94.080000 %\n",
      "Train - Epoch 83, Loss: 1.534067, Test Accuracy: 94.130000 %\n",
      "Train - Epoch 84, Loss: 1.606984, Test Accuracy: 93.820000 %\n",
      "Train - Epoch 85, Loss: 1.523651, Test Accuracy: 93.960000 %\n",
      "Train - Epoch 86, Loss: 1.513234, Test Accuracy: 93.230000 %\n",
      "Train - Epoch 87, Loss: 1.534067, Test Accuracy: 93.450000 %\n",
      "Train - Epoch 88, Loss: 1.513234, Test Accuracy: 93.620000 %\n",
      "Train - Epoch 89, Loss: 1.544484, Test Accuracy: 93.010000 %\n",
      "Train - Epoch 90, Loss: 1.544484, Test Accuracy: 94.230000 %\n",
      "Train - Epoch 91, Loss: 1.544430, Test Accuracy: 93.500000 %\n",
      "Train - Epoch 92, Loss: 1.544486, Test Accuracy: 93.180000 %\n",
      "Train - Epoch 93, Loss: 1.544484, Test Accuracy: 93.640000 %\n",
      "Train - Epoch 94, Loss: 1.492401, Test Accuracy: 93.760000 %\n",
      "Train - Epoch 95, Loss: 1.523651, Test Accuracy: 94.470000 %\n",
      "Train - Epoch 96, Loss: 1.534067, Test Accuracy: 94.490000 %\n",
      "Train - Epoch 97, Loss: 1.534067, Test Accuracy: 94.230000 %\n",
      "Train - Epoch 98, Loss: 1.575734, Test Accuracy: 94.440000 %\n",
      "Train - Epoch 99, Loss: 1.596567, Test Accuracy: 91.720000 %\n",
      "Train - Epoch 100, Loss: 1.534067, Test Accuracy: 92.300000 %\n",
      "Train - Epoch 101, Loss: 1.554901, Test Accuracy: 92.580000 %\n",
      "Train - Epoch 102, Loss: 1.554901, Test Accuracy: 92.910000 %\n",
      "Train - Epoch 103, Loss: 1.502817, Test Accuracy: 94.190000 %\n",
      "Train - Epoch 104, Loss: 1.544484, Test Accuracy: 94.080000 %\n",
      "Train - Epoch 105, Loss: 1.492401, Test Accuracy: 94.280000 %\n",
      "Train - Epoch 106, Loss: 1.565285, Test Accuracy: 94.180000 %\n",
      "Train - Epoch 107, Loss: 1.502817, Test Accuracy: 94.270000 %\n",
      "Train - Epoch 108, Loss: 1.606984, Test Accuracy: 94.230000 %\n",
      "Train - Epoch 109, Loss: 1.595930, Test Accuracy: 94.120000 %\n",
      "Train - Epoch 110, Loss: 1.544532, Test Accuracy: 94.390000 %\n",
      "Train - Epoch 111, Loss: 1.534067, Test Accuracy: 94.370000 %\n",
      "Train - Epoch 112, Loss: 1.492401, Test Accuracy: 94.540000 %\n",
      "Train - Epoch 113, Loss: 1.596567, Test Accuracy: 94.550000 %\n",
      "Train - Epoch 114, Loss: 1.534067, Test Accuracy: 94.920000 %\n",
      "Train - Epoch 115, Loss: 1.534067, Test Accuracy: 95.070000 %\n",
      "Train - Epoch 116, Loss: 1.544484, Test Accuracy: 93.910000 %\n",
      "Train - Epoch 117, Loss: 1.523651, Test Accuracy: 94.020000 %\n",
      "Train - Epoch 118, Loss: 1.534067, Test Accuracy: 94.770000 %\n",
      "Train - Epoch 119, Loss: 1.521792, Test Accuracy: 94.480000 %\n",
      "Train - Epoch 120, Loss: 1.513234, Test Accuracy: 94.610000 %\n",
      "Train - Epoch 121, Loss: 1.554901, Test Accuracy: 94.550000 %\n",
      "Train - Epoch 122, Loss: 1.586151, Test Accuracy: 94.730000 %\n",
      "Train - Epoch 123, Loss: 1.554901, Test Accuracy: 94.920000 %\n",
      "Train - Epoch 124, Loss: 1.540577, Test Accuracy: 94.910000 %\n",
      "Train - Epoch 125, Loss: 1.523651, Test Accuracy: 94.790000 %\n",
      "Train - Epoch 126, Loss: 1.554901, Test Accuracy: 94.910000 %\n",
      "Train - Epoch 127, Loss: 1.523651, Test Accuracy: 94.660000 %\n",
      "Train - Epoch 128, Loss: 1.554901, Test Accuracy: 94.740000 %\n",
      "Train - Epoch 129, Loss: 1.502817, Test Accuracy: 94.860000 %\n",
      "Train - Epoch 130, Loss: 1.502817, Test Accuracy: 94.940000 %\n",
      "Train - Epoch 131, Loss: 1.586151, Test Accuracy: 95.050000 %\n",
      "Train - Epoch 132, Loss: 1.509510, Test Accuracy: 94.820000 %\n",
      "Train - Epoch 133, Loss: 1.575734, Test Accuracy: 94.270000 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch 134, Loss: 1.513234, Test Accuracy: 94.270000 %\n",
      "Train - Epoch 135, Loss: 1.544484, Test Accuracy: 94.090000 %\n",
      "Train - Epoch 136, Loss: 1.523651, Test Accuracy: 94.240000 %\n",
      "Train - Epoch 137, Loss: 1.554862, Test Accuracy: 94.380000 %\n",
      "Train - Epoch 138, Loss: 1.513234, Test Accuracy: 94.250000 %\n",
      "Train - Epoch 139, Loss: 1.606984, Test Accuracy: 94.260000 %\n",
      "Train - Epoch 140, Loss: 1.565673, Test Accuracy: 93.570000 %\n",
      "Train - Epoch 141, Loss: 1.544484, Test Accuracy: 94.520000 %\n",
      "Train - Epoch 142, Loss: 1.513234, Test Accuracy: 94.510000 %\n",
      "Train - Epoch 143, Loss: 1.513234, Test Accuracy: 94.900000 %\n",
      "Train - Epoch 144, Loss: 1.502817, Test Accuracy: 95.090000 %\n",
      "Train - Epoch 145, Loss: 1.534067, Test Accuracy: 95.060000 %\n",
      "Train - Epoch 146, Loss: 1.502817, Test Accuracy: 94.840000 %\n",
      "Train - Epoch 147, Loss: 1.523651, Test Accuracy: 94.910000 %\n",
      "Train - Epoch 148, Loss: 1.565317, Test Accuracy: 94.860000 %\n",
      "Train - Epoch 149, Loss: 1.534067, Test Accuracy: 93.960000 %\n",
      "Train - Epoch 150, Loss: 1.596567, Test Accuracy: 94.460000 %\n",
      "Train - Epoch 151, Loss: 1.513234, Test Accuracy: 94.600000 %\n",
      "Train - Epoch 152, Loss: 1.565317, Test Accuracy: 93.170000 %\n",
      "Train - Epoch 153, Loss: 1.534067, Test Accuracy: 94.060000 %\n",
      "Train - Epoch 154, Loss: 1.565317, Test Accuracy: 94.370000 %\n",
      "Train - Epoch 155, Loss: 1.534067, Test Accuracy: 94.660000 %\n",
      "Train - Epoch 156, Loss: 1.523651, Test Accuracy: 94.730000 %\n",
      "Train - Epoch 157, Loss: 1.523651, Test Accuracy: 94.830000 %\n",
      "Train - Epoch 158, Loss: 1.501943, Test Accuracy: 94.430000 %\n",
      "Train - Epoch 159, Loss: 1.523651, Test Accuracy: 94.230000 %\n",
      "Train - Epoch 160, Loss: 1.523651, Test Accuracy: 94.330000 %\n",
      "Train - Epoch 161, Loss: 1.502817, Test Accuracy: 94.940000 %\n",
      "Train - Epoch 162, Loss: 1.575734, Test Accuracy: 93.610000 %\n",
      "Train - Epoch 163, Loss: 1.544484, Test Accuracy: 94.510000 %\n",
      "Train - Epoch 164, Loss: 1.523651, Test Accuracy: 94.750000 %\n",
      "Train - Epoch 165, Loss: 1.513234, Test Accuracy: 95.050000 %\n",
      "Train - Epoch 166, Loss: 1.534067, Test Accuracy: 95.070000 %\n",
      "Train - Epoch 167, Loss: 1.534067, Test Accuracy: 94.550000 %\n",
      "Train - Epoch 168, Loss: 1.481984, Test Accuracy: 94.610000 %\n",
      "Train - Epoch 169, Loss: 1.575734, Test Accuracy: 94.900000 %\n",
      "Train - Epoch 170, Loss: 1.523651, Test Accuracy: 94.310000 %\n",
      "Train - Epoch 171, Loss: 1.534067, Test Accuracy: 94.430000 %\n",
      "Train - Epoch 172, Loss: 1.534067, Test Accuracy: 94.320000 %\n",
      "Train - Epoch 173, Loss: 1.596567, Test Accuracy: 94.550000 %\n",
      "Train - Epoch 174, Loss: 1.565317, Test Accuracy: 94.370000 %\n",
      "Train - Epoch 175, Loss: 1.523651, Test Accuracy: 94.710000 %\n",
      "Train - Epoch 176, Loss: 1.502817, Test Accuracy: 94.880000 %\n",
      "Train - Epoch 177, Loss: 1.544484, Test Accuracy: 94.710000 %\n",
      "Train - Epoch 178, Loss: 1.481984, Test Accuracy: 94.650000 %\n",
      "Train - Epoch 179, Loss: 1.617401, Test Accuracy: 91.920000 %\n",
      "Train - Epoch 180, Loss: 1.513234, Test Accuracy: 93.710000 %\n",
      "Train - Epoch 181, Loss: 1.565317, Test Accuracy: 94.140000 %\n",
      "Train - Epoch 182, Loss: 1.575734, Test Accuracy: 94.810000 %\n",
      "Train - Epoch 183, Loss: 1.523651, Test Accuracy: 94.510000 %\n",
      "Train - Epoch 184, Loss: 1.565317, Test Accuracy: 94.830000 %\n",
      "Train - Epoch 185, Loss: 1.523651, Test Accuracy: 95.000000 %\n",
      "Train - Epoch 186, Loss: 1.544484, Test Accuracy: 95.010000 %\n",
      "Train - Epoch 187, Loss: 1.523651, Test Accuracy: 94.740000 %\n",
      "Train - Epoch 188, Loss: 1.481984, Test Accuracy: 94.940000 %\n",
      "Train - Epoch 189, Loss: 1.534067, Test Accuracy: 95.050000 %\n",
      "Train - Epoch 190, Loss: 1.575734, Test Accuracy: 94.910000 %\n",
      "Train - Epoch 191, Loss: 1.575734, Test Accuracy: 94.560000 %\n",
      "Train - Epoch 192, Loss: 1.523651, Test Accuracy: 94.180000 %\n",
      "Train - Epoch 193, Loss: 1.544484, Test Accuracy: 94.310000 %\n",
      "Train - Epoch 194, Loss: 1.617401, Test Accuracy: 94.220000 %\n",
      "Train - Epoch 195, Loss: 1.523651, Test Accuracy: 94.770000 %\n",
      "Train - Epoch 196, Loss: 1.586151, Test Accuracy: 94.770000 %\n",
      "Train - Epoch 197, Loss: 1.523651, Test Accuracy: 94.890000 %\n",
      "Train - Epoch 198, Loss: 1.554901, Test Accuracy: 94.940000 %\n",
      "Train - Epoch 199, Loss: 1.513234, Test Accuracy: 95.000000 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(total_epoch):  # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    model.apply(clipper)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Train - Epoch %d, Loss: %f, Test Accuracy: %f %%' \\\n",
    "          % (epoch, loss.detach().cpu().item(), 100 * correct / total))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = cwd+\"\\saved_model_state_dict\"+\"_\"+str(bitwidth)+\"_bitwidth_\"+str(layer_width)+\"_layerwidth_\"+str(lr)+\"_lr\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test load from state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95.000000 %\n"
     ]
    }
   ],
   "source": [
    "model_path = cwd+\"\\saved_model_state_dict\"+\"_\"+str(bitwidth)+\"_bitwidth_\"+str(layer_width)+\"_layerwidth_\"+str(lr)+\"_lr\"\n",
    "model = MLP3(layer_width)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "# model.apply(clipper)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-1., device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(0.1406, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1172, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(0.0859, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(-0.0938, device='cuda:0', grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight.max())\n",
    "print(model.fc1.weight.min())\n",
    "print(model.fc2.weight.max())\n",
    "print(model.fc2.weight.min())\n",
    "print(model.fc3.weight.max())\n",
    "print(model.fc3.weight.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
