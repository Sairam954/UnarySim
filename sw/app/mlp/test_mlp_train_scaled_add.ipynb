{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummaryX import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "from UnarySim.sw.kernel.nn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\project\\Anaconda3\\Lib\\site-packages\\UnarySim\\sw\\test\\mlp\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data loader\n",
    "transform=transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=cwd+'/../data/mnist', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root=cwd+'/../data/mnist', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "      Kernel Shape Output Shape  Params  Mult-Adds\n",
      "Layer                                             \n",
      "0_fc1  [1024, 512]     [1, 512]  524800     524288\n",
      "1_fc2   [512, 512]     [1, 512]  262656     262144\n",
      "2_fc3    [512, 10]      [1, 10]    5130       5120\n",
      "--------------------------------------------------\n",
      "                      Totals\n",
      "Total params          792586\n",
      "Trainable params      792586\n",
      "Non-trainable params       0\n",
      "Mult-Adds             791552\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_fc1</th>\n",
       "      <td>[1024, 512]</td>\n",
       "      <td>[1, 512]</td>\n",
       "      <td>524800</td>\n",
       "      <td>524288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_fc2</th>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>[1, 512]</td>\n",
       "      <td>262656</td>\n",
       "      <td>262144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_fc3</th>\n",
       "      <td>[512, 10]</td>\n",
       "      <td>[1, 10]</td>\n",
       "      <td>5130</td>\n",
       "      <td>5120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Kernel Shape Output Shape  Params  Mult-Adds\n",
       "Layer                                             \n",
       "0_fc1  [1024, 512]     [1, 512]  524800     524288\n",
       "1_fc2   [512, 512]     [1, 512]  262656     262144\n",
       "2_fc3    [512, 10]      [1, 10]    5130       5120"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = LeNet()\n",
    "# model = LeNet_clamp()\n",
    "model = MLP3()\n",
    "# model = MLP3_tanh()\n",
    "# model = MLP3_clamp()\n",
    "# model = MLP3_clamp_train()\n",
    "model.to(device)\n",
    "summary(model, torch.zeros((1, 1, 32, 32)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "clipper = NN_SC_Weight_Clipper(bitwidth=bitwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0691, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.0669, grad_fn=<MinBackward1>)\n",
      "tensor(0.0865, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.0809, grad_fn=<MinBackward1>)\n",
      "tensor(0.0671, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.0834, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 0, Loss: 1.588135, Test Accuracy: 91.180000 %\n",
      "tensor(0.0856, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.0819, grad_fn=<MinBackward1>)\n",
      "tensor(0.1105, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1088, grad_fn=<MinBackward1>)\n",
      "tensor(0.0774, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.0987, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 1, Loss: 1.595011, Test Accuracy: 92.510000 %\n",
      "tensor(0.0952, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.0960, grad_fn=<MinBackward1>)\n",
      "tensor(0.1314, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1315, grad_fn=<MinBackward1>)\n",
      "tensor(0.0842, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1105, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 2, Loss: 1.536012, Test Accuracy: 93.450000 %\n",
      "tensor(0.1055, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1121, grad_fn=<MinBackward1>)\n",
      "tensor(0.1484, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1482, grad_fn=<MinBackward1>)\n",
      "tensor(0.0891, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1202, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 3, Loss: 1.538309, Test Accuracy: 94.030000 %\n",
      "tensor(0.1152, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1240, grad_fn=<MinBackward1>)\n",
      "tensor(0.1605, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1612, grad_fn=<MinBackward1>)\n",
      "tensor(0.0934, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1298, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 4, Loss: 1.498328, Test Accuracy: 94.380000 %\n",
      "tensor(0.1225, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1345, grad_fn=<MinBackward1>)\n",
      "tensor(0.1690, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1700, grad_fn=<MinBackward1>)\n",
      "tensor(0.0965, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1388, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 5, Loss: 1.517056, Test Accuracy: 94.790000 %\n",
      "tensor(0.1305, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1442, grad_fn=<MinBackward1>)\n",
      "tensor(0.1790, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1760, grad_fn=<MinBackward1>)\n",
      "tensor(0.0998, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1472, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 6, Loss: 1.522072, Test Accuracy: 95.220000 %\n",
      "tensor(0.1368, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1533, grad_fn=<MinBackward1>)\n",
      "tensor(0.1887, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1848, grad_fn=<MinBackward1>)\n",
      "tensor(0.1028, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1559, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 7, Loss: 1.535895, Test Accuracy: 95.460000 %\n",
      "tensor(0.1438, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1591, grad_fn=<MinBackward1>)\n",
      "tensor(0.1989, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1927, grad_fn=<MinBackward1>)\n",
      "tensor(0.1055, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1640, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 8, Loss: 1.478061, Test Accuracy: 95.680000 %\n",
      "tensor(0.1481, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1673, grad_fn=<MinBackward1>)\n",
      "tensor(0.2066, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2002, grad_fn=<MinBackward1>)\n",
      "tensor(0.1084, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1716, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 9, Loss: 1.487565, Test Accuracy: 95.710000 %\n",
      "tensor(0.1529, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1760, grad_fn=<MinBackward1>)\n",
      "tensor(0.2150, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2057, grad_fn=<MinBackward1>)\n",
      "tensor(0.1105, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1788, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 10, Loss: 1.484785, Test Accuracy: 96.140000 %\n",
      "tensor(0.1568, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1841, grad_fn=<MinBackward1>)\n",
      "tensor(0.2216, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2106, grad_fn=<MinBackward1>)\n",
      "tensor(0.1131, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1848, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 11, Loss: 1.492114, Test Accuracy: 96.330000 %\n",
      "tensor(0.1589, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1925, grad_fn=<MinBackward1>)\n",
      "tensor(0.2269, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2142, grad_fn=<MinBackward1>)\n",
      "tensor(0.1195, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1921, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 12, Loss: 1.507502, Test Accuracy: 96.350000 %\n",
      "tensor(0.1619, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1989, grad_fn=<MinBackward1>)\n",
      "tensor(0.2314, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2183, grad_fn=<MinBackward1>)\n",
      "tensor(0.1250, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.1984, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 13, Loss: 1.489892, Test Accuracy: 96.810000 %\n",
      "tensor(0.1633, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2039, grad_fn=<MinBackward1>)\n",
      "tensor(0.2359, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2214, grad_fn=<MinBackward1>)\n",
      "tensor(0.1292, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2048, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 14, Loss: 1.483432, Test Accuracy: 96.760000 %\n",
      "tensor(0.1659, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2091, grad_fn=<MinBackward1>)\n",
      "tensor(0.2401, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2245, grad_fn=<MinBackward1>)\n",
      "tensor(0.1323, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2107, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 15, Loss: 1.496341, Test Accuracy: 96.850000 %\n",
      "tensor(0.1668, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2151, grad_fn=<MinBackward1>)\n",
      "tensor(0.2424, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2267, grad_fn=<MinBackward1>)\n",
      "tensor(0.1350, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2167, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 16, Loss: 1.471527, Test Accuracy: 97.060000 %\n",
      "tensor(0.1677, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2217, grad_fn=<MinBackward1>)\n",
      "tensor(0.2454, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2286, grad_fn=<MinBackward1>)\n",
      "tensor(0.1372, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2208, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 17, Loss: 1.478136, Test Accuracy: 97.100000 %\n",
      "tensor(0.1682, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2266, grad_fn=<MinBackward1>)\n",
      "tensor(0.2473, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2315, grad_fn=<MinBackward1>)\n",
      "tensor(0.1387, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2256, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 18, Loss: 1.463423, Test Accuracy: 97.140000 %\n",
      "tensor(0.1683, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2285, grad_fn=<MinBackward1>)\n",
      "tensor(0.2493, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2337, grad_fn=<MinBackward1>)\n",
      "tensor(0.1396, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2298, grad_fn=<MinBackward1>)\n",
      "Train - Epoch 19, Loss: 1.506345, Test Accuracy: 97.170000 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(model.fc1.weight.max())\n",
    "    print(model.fc1.weight.min())\n",
    "    print(model.fc2.weight.max())\n",
    "    print(model.fc2.weight.min())\n",
    "    print(model.fc3.weight.max())\n",
    "    print(model.fc3.weight.min())\n",
    "#     model.apply(clipper)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Train - Epoch %d, Loss: %f, Test Accuracy: %f %%' \\\n",
    "          % (epoch, loss.detach().cpu().item(), 100 * correct / total))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = cwd+\"\\saved_model_state_dict\"+\"_\"+str(bitwidth)+\"_no_clamp_new\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test load from state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 80.880000 %\n"
     ]
    }
   ],
   "source": [
    "model = MLP3_clamp_eval()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "# model.apply(clipper)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1683, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2285, grad_fn=<MinBackward1>)\n",
      "tensor(0.0785, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.0576, grad_fn=<MinBackward1>)\n",
      "tensor(0.2493, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2337, grad_fn=<MinBackward1>)\n",
      "tensor(0.0807, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.0598, grad_fn=<MinBackward1>)\n",
      "tensor(0.1396, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.2298, grad_fn=<MinBackward1>)\n",
      "tensor(0.0312, grad_fn=<MaxBackward1>)\n",
      "tensor(-0.0342, grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight.max())\n",
    "print(model.fc1.weight.min())\n",
    "print(model.fc1.bias.max())\n",
    "print(model.fc1.bias.min())\n",
    "\n",
    "print(model.fc2.weight.max())\n",
    "print(model.fc2.weight.min())\n",
    "print(model.fc2.bias.max())\n",
    "print(model.fc2.bias.min())\n",
    "\n",
    "print(model.fc3.weight.max())\n",
    "print(model.fc3.weight.min())\n",
    "print(model.fc3.bias.max())\n",
    "print(model.fc3.bias.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fc1.weight.data = model.fc1.weight*4\n",
    "# model.fc1.bias.data = model.fc1.bias*4\n",
    "\n",
    "# model.fc2.weight.data = model.fc2.weight*4\n",
    "# model.fc2.bias.data = model.fc2.bias*4\n",
    "\n",
    "# model.fc3.weight.data = model.fc3.weight*4\n",
    "# model.fc3.bias.data = model.fc3.bias*4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = cwd+\"\\saved_model_state_dict\"+\"_\"+str(bitwidth)+\"_no_clamp_new\"\n",
    "# torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MLP3_clamp_eval()\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "# model.eval()\n",
    "# model.to(device)\n",
    "# # model.apply(clipper)\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for data in testloader:\n",
    "#         images, labels = data[0].to(device), data[1].to(device)\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "#     100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.fc1.weight.max())\n",
    "# print(model.fc1.weight.min())\n",
    "# print(model.fc1.bias.max())\n",
    "# print(model.fc1.bias.min())\n",
    "\n",
    "# print(model.fc2.weight.max())\n",
    "# print(model.fc2.weight.min())\n",
    "# print(model.fc2.bias.max())\n",
    "# print(model.fc2.bias.min())\n",
    "\n",
    "# print(model.fc3.weight.max())\n",
    "# print(model.fc3.weight.min())\n",
    "# print(model.fc3.bias.max())\n",
    "# print(model.fc3.bias.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
